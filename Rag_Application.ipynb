{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPW6lzmsi8lj",
        "outputId": "bec791e2-a81a-4502-d172-177a92b9eae5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 2)) (0.1.16)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 3)) (0.1.3)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (0.0.34)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (0.1.46)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (0.1.50)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/requirements.txt (line 2)) (8.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai->-r /content/requirements.txt (line 3)) (1.23.6)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai->-r /content/requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf->-r /content/requirements.txt (line 4)) (4.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r /content/requirements.txt (line 2)) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r /content/requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain->-r /content/requirements.txt (line 2)) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain->-r /content/requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r /content/requirements.txt (line 2)) (3.10.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (4.66.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r /content/requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r /content/requirements.txt (line 2)) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r /content/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r /content/requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r /content/requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r /content/requirements.txt (line 2)) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r /content/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai->-r /content/requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai->-r /content/requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r /content/requirements.txt (line 2)) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FiWLtRY2iqtH"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS,DocArrayInMemorySearch\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZoB7cHiuiqtI"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "openai_api_key = \"sk-proj-N7E1cs97YAu6EmJTFsPqT3BlbkFJg2DwKsXrgsuW9XY3y82q\"\n",
        "Model = 'gpt-3.5-turbo'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPhfoIXziqtJ",
        "outputId": "08cc8089-87e8-4969-acac-01722b9253e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='I\\'m not sure what you mean by \"llama3.\" Could you please provide more context or clarify your question?', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 11, 'total_tokens': 35}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-04ed6d92-f5f6-43d4-bc7f-52f60203032e-0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = ChatOpenAI(api_key=openai_api_key,model=Model)\n",
        "model.invoke('llama3?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b5E-aXGSiqtM"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()\n",
        "chain = model|parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oYK6DjMKiqtM",
        "outputId": "7e7fe895-c5fc-454d-ab99-3087764ba5f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There is no specific definition for \"llama3.\" It is possible that it could be a typo or a made-up term. If you have any additional context or information, please provide it so I can better assist you.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "chain.invoke('what is llama3?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwlaKORQiqtM",
        "outputId": "a3455685-4828-446a-e979-11f45b85fb5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "file_loader = PyPDFLoader('llama3.pdf')\n",
        "page = file_loader.load_and_split()\n",
        "len(page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1caWLm6iqtN",
        "outputId": "4fe78f8c-55ef-45c6-817f-0208f4487031"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='state-of-the-art models using publicly available\\ndatasets exclusively, without resorting to\\nproprietary and inaccessible datasets. In\\nparticular, LLaMA-13B outperforms GPT-3', metadata={'source': 'llama3.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "spliter = RecursiveCharacterTextSplitter(chunk_size = 200,chunk_overlap = 50)\n",
        "pages = spliter.split_documents(page)\n",
        "pages[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FKDhq0D1iqtN"
      },
      "outputs": [],
      "source": [
        "vector_storage = FAISS.from_documents(pages,OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
        "retriever = vector_storage.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FliH2Fi4iqtN"
      },
      "outputs": [],
      "source": [
        "question_template = \"\"\"\n",
        "your a smart bot that answers questions based on the context given to you only.\n",
        "You don't make things up.\n",
        "context:{context}\n",
        "question:{question}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzJhlVGkiqtO",
        "outputId": "2c54bc9e-141e-4294-bf30-b181a2d25b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "your a smart bot that answers questions based on the context given to you only.\n",
            "You don't make things up.\n",
            "context: Here is the context to use\n",
            "question: Answer this question based on the context\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = PromptTemplate.from_template(template=question_template)\n",
        "print(prompt.format(context = ' Here is the context to use',\n",
        "              question = ' Answer this question based on the context'\n",
        "              ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ydr8M_zyiqtO"
      },
      "outputs": [],
      "source": [
        "result = RunnableParallel(context= retriever,question = RunnablePassthrough())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nju__g72iqtO"
      },
      "outputs": [],
      "source": [
        "chain = result |prompt | model | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "7xVW7XnziqtO",
        "outputId": "c0285580-7a8c-4280-ee92-123768be7825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the context provided, llama3 appears to refer to a model or system that is being compared to other models like GPT-3, Chinchilla, and PaLM in terms of performance on benchmarks. It is mentioned that llama3 models, such as LLaMA-13B and LLaMA-65B, outperform GPT-3 and are competitive with other models despite being smaller in size.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "chain.invoke('what is llama3?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "henboMNoiqtP",
        "outputId": "2bf51b56-9925-4c73-855f-ac6e794efdd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='portantly, the LLaMA-13B is also competitive on\\nthese benchmarks with GPT-3 and Chinchilla, de-\\nspite being 5-10 ×smaller. This model runs on a\\nsingle V100 GPU during inference.', metadata={'source': 'llama3.pdf', 'page': 4}),\n",
              " Document(page_content='particular, LLaMA-13B outperforms GPT-3\\n(175B) on most benchmarks, and LLaMA-65B\\nis competitive with the best models, Chinchilla-\\n70B and PaLM-540B. We release all our', metadata={'source': 'llama3.pdf', 'page': 0}),\n",
              " Document(page_content='notably, LLaMA-13B outperforms GPT-3 while\\nbeing more than 10 ×smaller, and LLaMA-65B is\\ncompetitive with Chinchilla-70B and PaLM-540B.\\nUnlike previous studies, we show that it is possible', metadata={'source': 'llama3.pdf', 'page': 10}),\n",
              " Document(page_content='to 65B parameters with competitive performance\\ncompared to the best existing LLMs. For instance,\\nLLaMA-13B outperforms GPT-3 on most bench-\\nmarks, despite being 10 ×smaller. We believe that', metadata={'source': 'llama3.pdf', 'page': 0})]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "retriever.invoke('what is llama3?')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6OLO_AUHNMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}